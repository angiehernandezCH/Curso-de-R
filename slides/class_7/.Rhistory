model.lmer <- lmer(Y ~ (1 | Group), data=Data)
vc    = VarCorr(model.lmer)                         # Variance components
vc    = data.frame(vc,order="lower.tri")
var_B = vc[2,4]; print(var_B)                       # Variance Between
var_W = vc[1,4]; print(var_W)                       # Variance Within
# Modeling dispersion
mod2 <- hglm(X = matrix(rep(1,n*k)), y = Y, Z = (I.k%x%One.n), family = gaussian(link = identity),
rand.family = gaussian(link = identity), method = "EQL",
conv = 1e-6, maxit = 1000, fixed = y ~ 1,
random = ~ 1 | Group, X.disp = model.matrix(~ Z), link.disp = "log",
X.rand.disp = list(model.matrix(~ z)), link.rand.disp = "log",
verbose= TRUE, data = Data)
summary(mod2)
##############################################################################################################################
Data_l1 <- data.frame(Y,Group,Z)
Data_l2 <- data.frame(group,z)
data <- list(N=n*k,J=k,y=Data_l1$Y,G=Data_l1$Group,Z=Data_l1$Z, g=Data_l2$group,z=Data_l2$z)
varying_intercept <- '
data {
int<lower=0> J;                   // number of groups (families)
int<lower=0> N;                   // number of obs (individuals)
int<lower=1, upper=J>  G[N];      // map obs to groups (individuals to families)
vector[N] y;                      // outcome
vector[J] z;                      // group level dispersion predictor
vector[N] Z;                      // individual level dispersion predictor
}
parameters {
vector[J] a;                           // Random Intercept
real theta_a0;                         // Intercept model for variance of random intercept
real theta_e0;                         // Intercept model for variance of residual error
real theta_a1;                         // Slope model for variance of random intercept
real theta_e1;                         // Slope model for variance of residual error
vector<lower=0>[J] sigma2_a;                    // Var for random intercept
vector<lower=0>[N] sigma2_e;                    // Var residual error
}
transformed parameters {
vector[N] y_mu;                       // Random effects
vector[J] logsigma2_a_mu;              // mean of log-Variance for random intercept
vector[J] sigma2_a_mu;                 // mean of Var for random intercept
vector[J] sigma_a;                     // Var for random intercept
vector[N] logsigma2_e_mu;              // mean of log-Variance residual error
vector[N] sigma2_e_mu;                 // mean of Var residual error
vector[N] sigma_e;                     // Var residual error
for (i in 1:J) {
// Assigns a different SD to each random intercept
logsigma2_a_mu[i] = theta_a0 + theta_a1*z[i];
sigma2_a_mu[i]    = exp(logsigma2_a_mu[i]);
sigma_a[i]       = sqrt(sigma2_a_mu[i]);
}
for (i in 1:N) {
// Assigns a different SD to each residual error
logsigma2_e_mu[i] = theta_e0 + theta_e1*Z[i];
sigma2_e_mu[i]    = exp(logsigma2_e_mu[i]);
sigma_e[i]       = sqrt(sigma2_e_mu[i]);
// Assigns a different predicted mean to ech individual depending of group of belonging
y_mu[i] = a[G[i]];
}
}
model {
theta_a0    ~ cauchy(0,2.5);
theta_e0    ~ cauchy(0,2.5);
theta_a1    ~ cauchy(0,2.5);
theta_e1    ~ cauchy(0,2.5);
sigma2_a ~ lognormal(sigma2_a_mu,0.25);
sigma2_e ~ lognormal(sigma2_e_mu,0.25);
a ~ normal(0, sigma_a);
y ~ normal(y_mu, sigma_e);
}
'
mymodel <- stan(model_code=varying_intercept, model_name="varying_intercept",
iter=1000, pars=c("theta_e0", "theta_e1","theta_a0", "theta_a1"), data=data, chains=2)
print(mymodel)
install_cmdstan(
dir = NULL,
cores = getOption("mc.cores", 8),
quiet = FALSE,
overwrite = FALSE,
timeout = 1200,
version = NULL,
release_url = NULL,
cpp_options = list(),
check_toolchain = TRUE
)
2+2
install_cmdstan(
dir = "/Users/mauricio",
cores = getOption("mc.cores", 8),
quiet = FALSE,
overwrite = FALSE,
timeout = 1200,
version = NULL,
release_url = NULL,
cpp_options = list(),
check_toolchain = TRUE
)
install_cmdstan(
dir = "/Users/mauricio",
cores = getOption("mc.cores", 8),
quiet = FALSE,
overwrite = TRUE,
timeout = 1200,
version = NULL,
release_url = NULL,
cpp_options = list(),
check_toolchain = TRUE
)
2+2
install_cmdstan(
dir = "/Users/mauricio",
cores = getOption("mc.cores", 8),
quiet = FALSE,
overwrite = TRUE,
timeout = 1200,
version = NULL,
release_url = NULL,
cpp_options = list(),
check_toolchain = TRUE
)
# we recommend running this is a fresh R session or restarting your current session
install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
library(cmdstanr)
check_cmdstan_toolchain()
install_cmdstan(cores = 8)
install_cmdstan(cores = 8, overwrite = TRUE)
set_cmdstan_path(cmdstan_path())
file <- file.path(cmdstan_path(), "examples", "bernoulli", "bernoulli.stan")
mod <- cmdstan_model(file)
data {
int<lower=0> N;
array[N] int<lower=0,upper=1> y; // or int<lower=0,upper=1> y[N];
}
parameters {
real<lower=0,upper=1> theta;
}
model {
theta ~ beta(1,1);  // uniform prior on interval 0,1
y ~ bernoulli(theta);
}
# names correspond to the data block in the Stan program
data_list <- list(N = 10, y = c(0,1,0,0,0,0,0,0,0,1))
fit <- mod$sample(
data = data_list,
seed = 123,
chains = 4,
parallel_chains = 4,
refresh = 500 # print update every 500 iters
)
fit$summary()
install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
remove.packages("cmdstanr")
install_cmdstan(
dir = NULL,
cores = getOption("mc.cores", 6),
quiet = FALSE,
overwrite = FALSE,
timeout = 1200,
version = NULL,
release_url = NULL,
cpp_options = list(),
check_toolchain = TRUE,
wsl = FALSE
)
# install.packages("remotes")
remotes::install_github("stan-dev/cmdstanr")
library("cmdstanr")
install_cmdstan(
dir = NULL,
cores = getOption("mc.cores", 6),
quiet = FALSE,
overwrite = FALSE,
timeout = 1200,
version = NULL,
release_url = NULL,
cpp_options = list(),
check_toolchain = TRUE,
wsl = FALSE
)
cmdstan_path()
library("cmdstanr")
cmdstan_path()
rebuild_cmdstan(
dir = cmdstan_path(),
cores = getOption("mc.cores", 6),
quiet = FALSE,
timeout = 600
)
1 + 1
#| echo: false
2 * 2
xaringan:::inf_mr()
xaringan:::inf_mr()
library("tinytex")
library("tidyverse")
library("vcd")
library("vcdExtra")
data("Yamaguchi87")
data <- Yamaguchi87
ctable <- xtabs(Freq ~ Son + Father+Country, data=Yamaguchi87)
ctable <- ctable[c(1,4),c(1,4),c(1,2)]
ctable_usa <- ctable[,,1]
ctable_uk  <- ctable[,,2]
library("tinytex")
library("tidyverse")
library("vcd")
library("vcdExtra")
data("Yamaguchi87")
data <- Yamaguchi87
ctable <- xtabs(Freq ~ Son + Father+Country, data=Yamaguchi87)
ctable <- ctable[c(1,4),c(1,4),c(1,2)]
ctable_usa <- ctable[,,1]
ctable_uk  <- ctable[,,2]
ctable_usa
ctable_uk
lapply(ctable_usa, sum, 1)
apply(ctable_usa, sum, 1)
?lapply
sapply(ctable_usa, sum, 1)
margins_son
ctable_usa
apply(ctable_usa, 1,sum)
margins_son    <- apply(ctable_usa, 1, sum)
margins_father <- apply(ctable_usa, 2, sum)
margins_son    <- apply(ctable_usa, 1, sum)/sum(ctable_usa)
margins_father <- apply(ctable_usa, 2, sum)/sum(ctable_usa)
margins_son
margins_father
margins_son %*% t(margins_father)
expected_frecs <- (margins_son %*% t(margins_father))*sum(ctable_usa)
expected_freqs <- (margins_son %*% t(margins_father))*sum(ctable_usa)
expected_freqs
ctable_usa - expected_freqs
expected_freqs
ctable_usa
1275 - 792.3817
2046 - 1563.382
sum((ctable_usa - expected_freqs)^2)
dchisqrt(0,1)
test_chiq <- sum(((ctable_usa - expected_freqs)^2)/ expected_freqs)
test_chiq
margins_son    <- apply(ctable_usa, 1, sum)/sum(ctable_usa)
margins_father <- apply(ctable_usa, 2, sum)/sum(ctable_usa)
expected_freqs <- (margins_son %*% t(margins_father))*sum(ctable_usa)
test_chi2 <- sum(((ctable_usa - expected_freqs)^2)/ expected_freqs)
1 - pchisq(test_chi2,df=1)
n = sum(ctable_usa)
margins_fila    <- apply(ctable_usa, 1, sum)/n
margins_columna <- apply(ctable_usa, 2, sum)/n
expected_freqs <- (margins_fila %*% t(margins_columna))*n
test_chi2 <- sum(((ctable_usa - expected_freqs)^2)/ expected_freqs)
p_value <- 1 - pchisq(test_chi2,df=1)
test_chi2
p_value
1-dchisqrt(0,1)
chisq.test(test_chi2,correct = FALSE)
?chisq.test
chisq.test(ctable_usa, correct = FALSE)
marginal_fila
mi_chi2 <- function(tabla) {
n = sum(tabla)
marginal_fila    <- apply(tabla, 1, sum)/n
marginal_columna <- apply(tabla, 2, sum)/n
frec_esperadas <- (marginal_fila %*% t(marginal_columna))*n
mi_chi2 <- sum(((tabla - frec_esperadas)^2)/ frec_esperadas)
mi_df <- (length(marginal_fila)-1)*(length(columna)-1)
mi_pvalue <- 1 - pchisq(mi_chi2, df=1)
}
mi_chi2(ctable_usa)
mi_chi2 <- function(tabla) {
n = sum(tabla)
marginal_fila    <- apply(tabla, 1, sum)/n
marginal_columna <- apply(tabla, 2, sum)/n
frec_esperadas <- (marginal_fila %*% t(marginal_columna))*n
mi_chi2 <- sum(((tabla - frec_esperadas)^2)/ frec_esperadas)
mi_df <- (length(marginal_fila)-1)*(length(marginal_columna)-1)
mi_pvalue <- 1 - pchisq(mi_chi2, df=1)
}
mi_chi2(ctable_usa)
mi_chi2 <- function(tabla) {
n = sum(tabla)
marginal_fila    <- apply(tabla, 1, sum)/n
marginal_columna <- apply(tabla, 2, sum)/n
frec_esperadas <- (marginal_fila %*% t(marginal_columna))*n
mi_chi2 <- sum(((tabla - frec_esperadas)^2)/ frec_esperadas)
mi_df <- (length(marginal_fila)-1)*(length(marginal_columna)-1)
mi_pvalue <- 1 - pchisq(mi_chi2, df=1)
print(list(chi2 = mi_chi2, pvalue = mi_pvalue))
}
mi_chi2(ctable_usa)
chisq.test(ctable_usa, correct = FALSE)
mi_chi2 <- function(tabla) {
n = sum(tabla)
marginal_fila    <- apply(tabla, 1, sum)/n
marginal_columna <- apply(tabla, 2, sum)/n
frec_esperadas <- (marginal_fila %*% t(marginal_columna))*n
mi_chi2 <- sum(((tabla - frec_esperadas)^2)/ frec_esperadas)
mi_df <- (length(marginal_fila)-1)*(length(marginal_columna)-1)
mi_pvalue <- 1 - pchisq(mi_chi2, df=1)
print(list(chi2 = mi_chi2, pvalue = mi_pvalue))
}
mi_chi2(ctable_usa)
chisq.test(ctable_usa, correct = FALSE)
mi_chi2(ctable_uk)
chisq.test((ctable_uk, correct = FALSE)
mi_chi2 <- function(tabla) {
n = sum(tabla)
marginal_fila    <- apply(tabla, 1, sum)/n
marginal_columna <- apply(tabla, 2, sum)/n
frec_esperadas <- (marginal_fila %*% t(marginal_columna))*n
mi_chi2 <- sum(((tabla - frec_esperadas)^2)/ frec_esperadas)
mi_df <- (length(marginal_fila)-1)*(length(marginal_columna)-1)
mi_pvalue <- 1 - pchisq(mi_chi2, df=1)
print(list(chi2 = mi_chi2, pvalue = mi_pvalue))
}
mi_chi2(ctable_usa)
chisq.test(ctable_usa, correct = FALSE)
mi_chi2(ctable_uk)
chisq.test(ctable_uk, correct = FALSE)
xaringan:::inf_mr()
---
## Triángulo OED (origen-educación-destino)
---
## Tendencias históricas
fdfg
xaringan:::inf_mr()
# Carga datos
library("readr")
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/Teaching/ISUC/2022_2_data_analysis_r/repo/slides/class_7/")
# leer archivo csv
data_casen_csv <- read_csv("sample_casen2017.csv")
data_casen_csv <- read_csv("https://raw.githubusercontent.com/mebucca/dar_soc4001/master/slides/class_6/sample_casen2017.csv")
# leer archivo csv desde github
data_casen_csv <- read_csv("https://raw.githubusercontent.com/mebucca/dar_soc4001/master/slides/class_6/sample_casen2017.csv")
## summarise: extrayendo información de los datos
library(tidyverse)
data_casen_csv %>%
summarise(mean_ytotcor = mean(ytotcor, na.rm = T))
data_casen_csv %>%
summarise(mean_ytotcor = mean(ytotcor, na.rm = T),
median_ytotcor = median(ytotcor, na.rm = T)) %>%
mutate(ratio = mean_ytotcor/median_ytotcor)
#Quantile:
data_casen_csv %>%
summarise(q20=quantile(ytotcor, probs=0.2, na.rm = T))
#3er caso:
data_casen_csv %>%
summarise(tercer=nth(ytotcor, n=5))
#Cantidad de valores distintos
data_casen_csv %>%
summarise(distintos=n_distinct(sexo))
## summarise across() variables
data_casen_csv %>%
summarise(across(c("sexo","edad") , mean))
data_casen_csv %>%
summarise(across( 2:4 , mean))
data_casen_csv %>%
summarise(across(starts_with("y"), mean))
data_casen_csv %>%
summarise(across(starts_with("y"), ~mean(.x, na.rm = TRUE) ))
data_casen_csv %>%
summarise(across(contains("ed"), ~mean(.x, na.rm = TRUE) ))
## summarise una variable con una lista de funciones
data_casen_csv %>%
summarise(across(edad, list(media = mean, mediana = median)))
data_casen_csv %>%
summarise(across(ytrabajocor, list(media =  ~mean(.x, na.rm = TRUE), mediana = ~median(.x, na.rm = TRUE))))
data_casen_csv %>%
summarise(across(c("edad","ytrabajocor"), list(average =  ~mean(.x, na.rm = TRUE), q50 = ~median(.x, na.rm = TRUE))))
## summarise muchas variable con una lista de funciones
data_casen_csv %>%
summarise(across(starts_with("y"), list(media = ~mean(.x, na.rm = TRUE), mediana= ~median(.x, na.rm = TRUE)) ))
## summarise by_group(): resumiendo datos agupados
mitabla <- data_casen_csv %>%
mutate(edad_cat = case_when(edad <= 18 ~ "menores",
edad >18 & edad<=65 ~ "adultos",
edad > 65  ~ "adultos mayores")) %>%
group_by(region, sexo, edad_cat) %>%
summarise(mean_ytotcor = mean(ytotcor, na.rm = T),
median_ytotcor = median(ytotcor, na.rm = T)) %>%
mutate(ratio = mean_ytotcor/median_ytotcor) %>%
arrange(desc(ratio))
# Combinando herramientas
data_casen_csv %>%
group_by(region, sexo) %>%
summarise(across(ytrabajocor, list(media =  ~mean(.x, na.rm = TRUE), mediana = ~median(.x, na.rm = TRUE))))
## join: juntar bases de datos
data_a <- data_casen_csv %>% filter(region <2 | region>=15 ) %>%
group_by(region) %>%
summarise(across(edad, mean)); data_a
data_b <- data_casen_csv %>% filter(region <3 | region>=16 ) %>%
group_by(region) %>%
summarise(across(c(edad,yautcorh), mean)); data_b
#`inner_join()`
data_a   %>% inner_join(data_b, by="region")
data_b   %>% inner_join(data_a, by="region")
data_a %>% inner_join(data_b %>% select(!edad), by="region")
data_a %>% select(!edad) %>% inner_join(data_b, by="region")
#`left_join()`
data_a %>% left_join(data_b  %>% select(!edad), by="region")
#`right_join()`
data_a  %>% right_join(data_b %>% select(!edad), by="region")
#`full_join()`
data_a  %>% full_join(data_b %>% select(!edad), by="region")
#`full_join()`
data_a  %>% full_join(data_b, by="region") %>%
mutate(edad = if_else(is.na(edad.x),edad.y,edad.x)) %>%
select(!c(edad.x,edad.y))
data_a  %>% full_join(data_b, by="region") %>%
rowwise() %>%
mutate(edad = max(edad.x, edad.y, na.rm = T)) %>%
select(!c(edad.x,edad.y))
## join: juntar bases de datos por más de una llave
mitabla
data_casen_csv %>%
mutate(edad_cat = case_when(edad <= 18 ~ "menores",
edad >18 & edad<=65 ~ "adultos",
edad > 65  ~ "adultos mayores")) %>%
left_join(mitabla, by=c("region","sexo", "edad_cat")) %>%
select(region,sexo,mean_ytotcor, median_ytotcor, ratio)
library(haven)
Casen2017 <- read_dta("~/Desktop/Casen 2017.dta")
library(haven)
Casen2017 <- read_dta("~/Desktop/Casen 2017.dta")
library(haven)
Casen2017 <- read_dta("~/Desktop/Casen 2017.dta")
Casen2017
Casen2017 %>% select(r12a,r12b,educ) %>% mutate(across(c("r12a","r12b")), casen_when(
.x==1 ~ 0,
.x==2 ~ 6,
.x==3 ~ 6,
.x==4 ~ 12,
.x==5 ~ 12,
.x==6 ~ 12,
.x==7 ~ 12,
.x==7 ~ 12,
.x==8 ~ 14,
.x==9 ~ 17,
.x==10 ~ 20
)
)
Casen2017 %>% select(r12a,r12b,educ) %>% mutate(across(c("r12a","r12b")), case_when(
.x==1 ~ 0,
.x==2 ~ 6,
.x==3 ~ 6,
.x==4 ~ 12,
.x==5 ~ 12,
.x==6 ~ 12,
.x==7 ~ 12,
.x==7 ~ 12,
.x==8 ~ 14,
.x==9 ~ 17,
.x==10 ~ 20
)
)
Casen2017 %>% select(r12a,r12b,educ) %>% mutate(across(c("r12a","r12b"), case_when(
.x==1 ~ 0,
.x==2 ~ 6,
.x==3 ~ 6,
.x==4 ~ 12,
.x==5 ~ 12,
.x==6 ~ 12,
.x==7 ~ 12,
.x==7 ~ 12,
.x==8 ~ 14,
.x==9 ~ 17,
.x==10 ~ 20
))
)
Casen2017 %>% select(r12a,r12b,educ) %>% mutate(across(c("r12a","r12b")), ~ case_when(
.x==1 ~ 0,
.x==2 ~ 6,
.x==3 ~ 6,
.x==4 ~ 12,
.x==5 ~ 12,
.x==6 ~ 12,
.x==7 ~ 12,
.x==7 ~ 12,
.x==8 ~ 14,
.x==9 ~ 17,
.x==10 ~ 20
)
)
Casen2017 %>% select(r12a,r12b,educ) %>% mutate(across(c("r12a","r12b"), ~ case_when(
.x==1 ~ 0,
.x==2 ~ 6,
.x==3 ~ 6,
.x==4 ~ 12,
.x==5 ~ 12,
.x==6 ~ 12,
.x==7 ~ 12,
.x==7 ~ 12,
.x==8 ~ 14,
.x==9 ~ 17,
.x==10 ~ 20
))
)
Casen2017 %>% select(r12a,r12b,educ)
Casen2017 %>% select(r12a,r12b,esc) %>% mutate(across(c("r12a","r12b"), ~ case_when(
.x==1 ~ 0,
.x==2 ~ 6,
.x==3 ~ 6,
.x==4 ~ 12,
.x==5 ~ 12,
.x==6 ~ 12,
.x==7 ~ 12,
.x==7 ~ 12,
.x==8 ~ 14,
.x==9 ~ 17,
.x==10 ~ 20
))
) %>%
rowwise() %>%
mutate(esc_p = max(r12a,r12b, na.rm = T))
